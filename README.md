# 금융 상품 추천 시스템 (FinShibainu 기반)

## 1. 프로젝트 개요

이 프로젝트는 **오픈소스로 공개된 LLM(대규모 언어 모델)**을 활용하여, 금융 상품(적금, 펀드, ETF 등) 추천을 위한 AI 기반 시스템을 구축하는 것을 목표로 합니다.
구체적으로 **모듈러 RAG (Modular RAG)** 기법을 적용하여, 사용자의 투자 성향·목적·자금 규모 등을 분석하고, 인터넷에서 공개적으로 수집한 각 은행·증권사의 금융 상품 정보를 벡터 데이터베이스로 구축하여 사용자 맞춤형 추천을 제공합니다.

- 데이터 수집:
인터넷(공개 웹 페이지, 금융사 홈페이지, 금융 포털 등)을 통해 은행별 적금, 펀드, ETF 등의 상품 특징과 장단점을 확보
수집한 텍스트를 전처리 후 벡터 임베딩하여 벡터 데이터베이스에 저장

- 질의 처리:
사용자의 투자 성향, 금융상품 탐색 목적, 자금 출처 및 규모 등을 쿼리로 받아, 관련된 금융 상품을 벡터 검색으로 조회
LLM 모델을 통해 결과 요약 및 핵심 정보를 추론하여 사용자에게 반환
이 과정을 통해 정확하고 개인화된 금융 상품 추천 시스템을 구성하는 것이 이 프로젝트의 핵심 목표입니다.

---

## 2. 사용 모델 및 이유

### **FinShibainu 모델**
이 시스템은 **Hugging Face에서 제공하는 "FinShibainu" 모델**을 사용합니다.
FinShibainu는 금융 및 회계 등 금융 관련 지식 기반 텍스트 생성을 위해 특화된 언어 모델이며, KRX LLM 경진대회 리더보드에서 우수상을 수상한 shibainu24 모델을 기반으로 하고 있습니다.
해당 모델은 금융 도메인에서 활용하기 적합한 높은 성능과 효율성을 자랑하며, 오픈소스로 공개되어 있어 손쉽게 활용 및 확장이 가능합니다.

**출처:** [Hugging Face - FinShibainu](https://huggingface.co/FinShibainu)

---
### 모델 개요

- **베이스 모델**: Qwen2.5-7B-Instruct  
  FinShibainu는 Qwen2.5-7B-Instruct를 베이스로 하여 금융 분야에 맞게 파인튜닝되었습니다.
  
- **정밀도 (dtype)**: bfloat16  
  모델의 모든 텐서는 bfloat16 정밀도로 구성되어, 연산 효율성과 메모리 사용의 균형을 맞추고 있습니다.

- **PEFT (Parameter-Efficient Fine-Tuning)**: LoRA  
  - **r (rank)**: 8  
  - **alpha**: 64  
  LoRA를 통한 파인튜닝 기법을 적용하여, 기존 대형 모델의 파라미터 전체를 재학습하지 않고도 금융 특화 성능을 확보했습니다.

- **학습 관련 설정**:  
  - **Learning Rate**: 1e-5 (추가 학습에 따라 달라질 수 있음)  
  - **Learning Rate Scheduler**: Cosine 스케줄러 (warm-up: 전체 학습의 0.05%)  
  - **Optimizer**: AdamW

- **분산 및 효율적 튜닝**:  
  - **DeepSpeed v3**와 **Flash Attention** 기술을 활용하여 대규모 모델의 효율적인 학습 및 추론을 지원합니다.

- **Vanilla 모델**: Qwen2.5-7B-Instruct  
  FinShibainu는 Qwen2.5-7B-Instruct 모델을 금융, 회계 도메인 데이터로 파인튜닝하여 개발되었습니다.

- **관련 코드**:  
  데이터셋 수집 및 학습 관련 코드는 [GitHub - aiqwe/FinShibainu](https://github.com/aiqwe/FinShibainu)에서 확인할 수 있습니다.

---

### 모델 구조

FinShibainu의 내부 구조는 대형 언어 모델의 전형적인 Transformer 기반 아키텍처를 따릅니다.

- **임베딩 레이어**:  
  - `model.embed_tokens.weight`: 토큰 임베딩 행렬, 크기 `[152,064, 3,584]` (BF16)

- **Transformer 레이어 (총 28개 레이어)**:  
  모든 레이어의 텐서는 BF16 정밀도로 구성되어 있으며, 금융 도메인에 특화된 텍스트 생성을 위해 최적화되어 있습니다.

- **최종 정규화 및 출력 헤드**:  
  - 최종 LayerNorm: `model.norm.weight` (크기 `[3,584]`)
  - 출력 레이어 (LM Head): `lm_head.weight` (크기 `[152,064, 3,584]`)

- **Quantization**:  
  - FinShibainu 모델은 두 가지 양자화(Quantization) 버전으로 제공됩니다.

- **모델 트리**:  
  - 베이스 모델: `Qwen/Qwen2.5-7B`
  - 파인튜닝된 모델: `Qwen/Qwen2.5-7B-Instruct` → FinShibainu (aiqwe/FinShibainu)

---

#### 특징 및 활용

- **금융 도메인 특화**:  
  금융상품, 금융 리포트, 회계 관련 텍스트 생성을 위한 데이터로 파인튜닝되어, 금융 분야에서의 질의응답, 리포트 요약, 추천 시스템 등에 활용할 수 있습니다.

- **효율적 파인튜닝**:  
  LoRA 기법을 적용하여 적은 파라미터만을 추가 학습함으로써, 대규모 모델의 장점을 유지하면서도 리소스 부담을 줄였습니다.

- **최적화된 학습 및 추론**:  
  DeepSpeed와 Flash Attention을 통해 대용량 모델의 학습 및 실시간 추론 속도를 향상시켰습니다.

- **경쟁력 있는 성능**:  
  KRX LLM 경진대회에서 우수상을 수상한 만큼, 금융 및 회계 관련 텍스트 생성 작업에서 높은 성능을 입증받았습니다.


### **사용 이유**
- **금융 특화 모델**: 금융 및 회계 관련 데이터를 학습하여 금융 도메인에 최적화됨
- **자연어 처리 성능**: 범용 LLM보다 금융 데이터를 정확하게 이해하고 응답 가능
- **오픈소스 라이선스**: 자유롭게 사용 및 확장 가능

---

## 3. 시스템 개요 및 구조

이 시스템은 **모듈러 RAG**를 활용하여 구축되며, **LangChain**을 기반으로 RAG 파이프라인을 구현합니다. 모듈화된 구조를 통해 검색(Retrieval)과 생성(Generation) 과정을 분리하고, 각 모듈을 독립적으로 최적화할 수 있습니다.


### 데이터 수집

**인터넷 기반 정보 수집**
은행, 증권사 웹사이트, 금융 관련 포털 등에서 적금·펀드·ETF의 상품 특성, 조건, 장단점 등 텍스트 데이터를 크롤링/수집
수집된 데이터에 대한 전처리(중복 제거, 텍스트 정제 등) 수행

**임베딩 및 벡터 데이터베이스 구축**
전처리된 금융 상품 정보를 문장 임베딩으로 변환
임베딩 모델은 Sentence-Transformers에서 제공되는 all-MiniLM-L6-v2을 사용
백터 데이터베이스는 ChromaDB을 사용


### 프로세스
```plaintext
[데이터 수집 및 전처리]
        │
        ▼
[텍스트 임베딩 생성 및 벡터 저장]
        │
        ▼
[벡터 데이터베이스 구축]
        │
        ▼
[사용자 쿼리 입력 (웹 인터페이스)]
        │
        ▼
[벡터 검색 (유사 금융 상품 탐색)]
        │
        ▼
[LLM 프롬프트 구성 및 추천 결과 생성]
        │
        ▼
[사용자에게 추천 금융 상품 표시]
```

**사용자 쿼리 입력**:
사용자로부터 투자 성향, 금융상품 탐색 목적, 자금 출처 및 규모 등을 입력받음

**벡터 검색**:
벡터 데이터베이스에 쿼리를 임베딩하고, 가장 유사한 금융 상품 정보를 검색

**LLM 기반 응답 생성**:
FinShibainu 모델로 검색된 금융 상품 특징을 종합 분석
사용자 맞춤형 요약 및 추천 정보를 생성

**결과 반환**:
사용자에게 적합한 금융 상품(적금, 펀드, ETF 등)의 장단점과 핵심 정보를 전달

---

## 4. 사용 알고리즘 및 기술

### (1) **모듈러 RAG (Modular RAG) 기법**
- **이유**: 최신 금융 데이터를 검색하여 더욱 정확한 정보를 제공하기 위해 사용됨
- **특징**:
  - 검색(retrieval)과 생성(generation) 모듈 분리
  - 다양한 데이터 소스를 활용할 수 있도록 유연하게 설계
  - 검색 및 생성 모듈을 개별적으로 최적화 가능

#### **구성 요소**
- **Retriever**: FAISS 벡터 검색을 통해 적절한 금융 상품 탐색
- **Generator**: FinShibainu 모델을 활용하여 사용자 맞춤형 추천 응답 생성

### (2) **LangChain을 활용한 RAG 파이프라인**
- **이유**: LangChain을 사용하면 RAG 파이프라인을 쉽게 구성하고 확장 가능

#### **구성 요소**
- **RetrievalQA 체인**을 활용하여 검색 + 생성 통합
- **벡터 데이터베이스와 LLM**을 연결하여 금융 상품 정보 제공
- **프롬프트 엔지니어링**을 통해 응답 품질 향상

### (3) **벡터 데이터베이스 (ChromaDB)**
- **이유**: 오픈소스로 무료로 사용이 가능하고 메모리 기반 벡터 저장소 빠른 검색과 유사도를 비교를 보장하며 데이터 변경이 자유로움 
- **구현**: `sentence-transformers`를 활용하여 금융 상품 설명을 벡터로 변환 후 저장

### (4) **LLM (FinShibainu) 기반 자연어 처리**
- **이유**: 사용자의 투자 목적, 가입 조건, 자금 규모 등 다양한 요소를 고려하여 적절한 상품을 추천하기 위함
- **활용 기술**: `transformers` 라이브러리 기반의 FinShibainu 모델

---

## 5. 데이터 학습 및 사용자 인터페이스

### (1) 데이터 학습 및 파인튜닝
- 금융 상품 데이터셋을 전처리하여 텍스트 임베딩 생성
- Chromadb에 벡터화하여 저장
- 추가적인 금융 도메인 데이터로 **FinShibainu 모델 파인튜닝 가능**

### (2) 사용자 인터페이스 (UI)
- **Gradio 기반 웹 인터페이스 제공**
- 사용자는 텍스트 입력창을 통해 금융 상품 추천 요청 가능
- **모델의 추천 프로세스**
  1. 사용자 입력
  2. 금융 상품 검색
  3. LLM 생성
  4. 추천 결과 반환

---

## 6. 설치 및 실행 방법

### (1) 환경 설정
```bash
# 프로젝트 클론
git clone https://github.com/your-repo/project_name.git
cd project_name

# 가상 환경 생성 및 활성화
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 필요한 라이브러리 설치
pip install -r requirements.txt
```

### (2) 시스템 실행
#### 1. 데이터 전처리 및 벡터 생성
```bash
python src/data_processing.py
python src/embedding.py
```

#### 2. 모델 로드 및 RAG 파이프라인 실행
```bash
python src/rag_pipeline.py
```

#### 3. 웹 인터페이스 실행
```bash
python src/app.py
```

---

## 7. 결론 및 기대 효과

이 시스템은 **전통적인 금융 추천 시스템과 달리 최신 데이터를 활용하는 모듈러 RAG 기법**을 사용하여 **더욱 신뢰성 높은 금융 상품 추천**을 제공합니다.

### **기대 효과**
- 사용자는 본인의 투자 성향에 맞는 상품을 보다 정확하게 추천받을 수 있음
- 금융 기업은 **개인 맞춤형 추천 서비스**를 보다 효과적으로 운영할 수 있음

---

**문의 및 기여**
- 본 프로젝트에 대한 기여를 환영합니다. Pull Request 또는 Issue를 통해 의견을 공유해주세요!
